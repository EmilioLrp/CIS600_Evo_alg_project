# -*- coding: utf-8 -*-
"""ES_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ISoelBRREWPwPhD7Ws6K26P6c6sIuBb
"""

import numpy as np
from scipy.special import softmax
from data_util import load_data_mat

# Define ES parameters
POP_SIZE = 50
NUM_GENERATIONS = 100
MUTATION_RATE = 0.4
CROSSOVER_RATE = 0.7
NUM_PARENTS = 2
INPUT_SIZE = 16 * 26
OUTPUT_SIZE = 26
LOWER_BOUND = -5.0
UPPER_BOUND = 5.0

# Generate random train and test sets
# TRAIN_SIZE = 1000
# TEST_SIZE = 100
# train_inputs = np.random.rand(TRAIN_SIZE, 16)
# test_inputs = np.random.rand(TEST_SIZE, 16)
# train_labels = np.random.randint(0, 26, size=(TRAIN_SIZE,))
# test_labels = np.random.randint(0, 26, size=(TEST_SIZE,))
train_inputs, test_inputs, train_labels_onehot, test_labels_onehot = load_data_mat()
# train_labels_onehot = np.zeros((TRAIN_SIZE, 26))
# train_labels_onehot[np.arange(TRAIN_SIZE), train_labels] = 1
# test_labels_onehot = np.zeros((TEST_SIZE, 26))
# test_labels_onehot[np.arange(TEST_SIZE), test_labels] = 1

# Define fitness function
def evaluate(individual, inputs, labels):
    outputs = softmax(np.dot(inputs, individual.reshape(16, 26)))
    predictions = np.argmax(outputs, axis=1)
    correct_predictions = np.sum(predictions == np.argmax(labels, axis=1))
    fitness = correct_predictions / inputs.shape[0]
    return fitness

# Initialize population with random individuals
pop = np.random.uniform(LOWER_BOUND, UPPER_BOUND, size=(POP_SIZE, INPUT_SIZE))

# Initialize standard deviation for mutation
sigma = np.ones(INPUT_SIZE)

# Main ES loop
for gen in range(NUM_GENERATIONS):
    # Evaluate fitness of each individual
    fitnesses = np.zeros(POP_SIZE)
    for i in range(POP_SIZE):
        fitnesses[i] = evaluate(pop[i], train_inputs, train_labels_onehot)
    
    # Sort population by fitness
    sorted_indices = np.argsort(fitnesses)[::-1] # Sort in descending order
    pop = pop[sorted_indices]
    fitnesses = fitnesses[sorted_indices]
    
    # Print current best fitness
    print("Generation {}: Best fitness = {}".format(gen, fitnesses[0]))
    
    # Update standard deviation for mutation
    sigma = sigma * np.exp(0.2 * np.random.randn(INPUT_SIZE))
    
    # Initialize new population
    new_pop = np.zeros_like(pop)
    
    # Elitism: Keep best individual from previous generation
    new_pop[0] = pop[0]
    
    # Generate offspring through selection, mutation, and crossover
    for i in range(1, POP_SIZE):
        # Selection
        parents = pop[np.random.choice(POP_SIZE, size=NUM_PARENTS, replace=False)]
        
        # Mutation
        mutations = np.random.normal(scale=sigma, size=INPUT_SIZE)
        offspring = parents[0] + mutations
        offspring = np.clip(offspring, LOWER_BOUND, UPPER_BOUND)
        
        # Crossover
        if np.random.rand() < CROSSOVER_RATE:
            crossover_point1 = np.random.randint(INPUT_SIZE)
            crossover_point2 = np.random.randint(INPUT_SIZE)
            if crossover_point1 > crossover_point2:
                crossover_point1, crossover_point2 = crossover_point2, crossover_point1
            offspring[crossover_point1:crossover_point2] = parents[1][crossover_point1:crossover_point2]
        
        new_pop[i] = offspring
    
    # Update population
    pop = new_pop
    
    # Evaluate best individual on testing data
    # Evaluate best individual on testing data
    best_individual = pop[0]
    test_fitness = evaluate(best_individual, test_inputs, test_labels_onehot)
    print("Generation {}: Test fitness = {}".format(gen, test_fitness))