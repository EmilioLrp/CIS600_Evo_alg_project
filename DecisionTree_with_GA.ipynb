{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEAjcnfDzUOb",
        "outputId": "488c8eb4-3b2e-4be0-f3b2-38130815f1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-3e92aaa639fe>:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  training_points = np.array(letters[:15000].drop(['letter'], 1))\n",
            "<ipython-input-2-3e92aaa639fe>:16: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  test_points = np.array(letters[1500:].drop(['letter'], 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9648648648648649\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      0.98      0.98       729\n",
            "           B       0.93      0.97      0.95       702\n",
            "           C       0.97      0.96      0.97       685\n",
            "           D       0.95      0.97      0.96       736\n",
            "           E       0.95      0.95      0.95       714\n",
            "           F       0.96      0.96      0.96       728\n",
            "           G       0.97      0.95      0.96       716\n",
            "           H       0.93      0.93      0.93       667\n",
            "           I       0.98      0.97      0.97       700\n",
            "           J       0.97      0.97      0.97       672\n",
            "           K       0.96      0.96      0.96       680\n",
            "           L       0.98      0.98      0.98       709\n",
            "           M       0.98      0.98      0.98       718\n",
            "           N       0.97      0.96      0.97       726\n",
            "           O       0.96      0.97      0.96       702\n",
            "           P       0.95      0.96      0.96       736\n",
            "           Q       0.96      0.96      0.96       734\n",
            "           R       0.96      0.94      0.95       707\n",
            "           S       0.96      0.95      0.96       680\n",
            "           T       0.98      0.97      0.97       738\n",
            "           U       0.97      0.98      0.98       761\n",
            "           V       0.98      0.97      0.98       708\n",
            "           W       0.99      0.98      0.99       715\n",
            "           X       0.96      0.97      0.96       728\n",
            "           Y       0.96      0.96      0.96       723\n",
            "           Z       0.97      0.97      0.97       686\n",
            "\n",
            "    accuracy                           0.96     18500\n",
            "   macro avg       0.96      0.96      0.96     18500\n",
            "weighted avg       0.96      0.96      0.96     18500\n",
            "\n",
            "[[714   0   0   1   1   0   1   2   0   0   1   1   2   0   1   0   0   0\n",
            "    0   0   1   1   0   1   2   0]\n",
            " [  0 680   0   3   0   1   0   3   1   0   0   0   0   0   1   2   0   5\n",
            "    1   2   0   1   0   1   0   1]\n",
            " [  3   0 661   0   8   1   3   1   0   0   0   1   0   1   2   0   0   0\n",
            "    0   1   1   0   0   0   2   0]\n",
            " [  0   2   0 713   0   1   0   5   1   0   0   0   0   3   2   2   0   4\n",
            "    0   0   0   0   0   1   1   1]\n",
            " [  0   1   3   0 678   4   3   0   0   0   0   2   0   0   0   1   3   3\n",
            "    5   0   0   0   0   5   0   6]\n",
            " [  0   1   1   0   1 698   0   2   3   1   0   1   0   3   0  12   1   0\n",
            "    0   1   0   0   0   1   2   0]\n",
            " [  0   3   5   0   3   1 680   2   0   3   2   1   0   0   4   2   3   1\n",
            "    1   2   1   0   1   1   0   0]\n",
            " [  0  11   0   4   3   1   1 617   0   2   6   0   0   2   2   2   0   6\n",
            "    3   0   4   1   1   1   0   0]\n",
            " [  1   1   0   0   1   1   0   0 677   3   0   0   0   1   0   1   1   0\n",
            "    2   1   0   0   0   5   1   4]\n",
            " [  1   0   1   2   3   1   0   0   3 653   0   0   0   0   1   1   0   0\n",
            "    2   0   1   0   1   0   0   2]\n",
            " [  0   3   1   1   3   2   1   7   0   0 652   0   0   0   0   1   1   3\n",
            "    1   1   0   0   0   3   0   0]\n",
            " [  0   0   3   0   1   1   1   1   0   1   1 696   0   1   1   0   0   0\n",
            "    2   0   0   0   0   0   0   0]\n",
            " [  1   0   1   0   0   0   0   0   0   2   0   0 706   2   0   0   2   1\n",
            "    0   0   1   0   2   0   0   0]\n",
            " [  0   3   1   2   0   2   0   2   0   0   2   1   2 699   4   0   0   1\n",
            "    0   0   1   2   1   0   3   0]\n",
            " [  0   1   2   3   0   0   2   3   0   0   0   1   0   0 679   0   5   0\n",
            "    0   1   2   1   1   1   0   0]\n",
            " [  0   3   0   0   0   5   1   1   2   1   0   0   0   0   3 709   2   1\n",
            "    0   0   1   1   1   2   3   0]\n",
            " [  0   2   2   4   3   0   2   1   0   0   1   0   0   0   5   0 704   1\n",
            "    2   0   5   1   0   0   0   1]\n",
            " [  0   9   1   5   0   0   0   3   0   0   5   2   1   2   2   3   3 667\n",
            "    0   0   0   1   0   2   0   1]\n",
            " [  1   2   0   2   3   1   1   5   2   2   0   1   0   0   0   0   2   0\n",
            "  649   1   0   0   0   4   0   4]\n",
            " [  1   1   0   0   0   5   0   1   0   1   0   1   0   0   1   0   0   0\n",
            "    1 717   0   0   1   0   6   2]\n",
            " [  1   0   1   2   0   0   1   1   0   0   0   0   2   2   1   0   1   1\n",
            "    0   2 744   0   0   1   1   0]\n",
            " [  0   3   0   0   0   0   1   0   0   0   0   0   0   0   0   3   2   1\n",
            "    0   0   0 690   0   0   8   0]\n",
            " [  0   0   0   0   0   1   2   0   0   0   0   0   3   2   1   0   0   1\n",
            "    0   0   0   1 703   0   1   0]\n",
            " [  0   3   0   2   3   1   0   1   0   3   7   1   0   0   0   0   0   0\n",
            "    1   0   2   0   0 704   0   0]\n",
            " [  0   1   0   3   0   1   0   2   0   1   0   0   1   0   0   2   1   0\n",
            "    3   4   1   5   0   0 697   1]\n",
            " [  0   1   0   4   4   0   0   0   0   0   0   3   0   0   0   2   1   1\n",
            "    6   0   0   0   0   1   0 663]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "letters = pd.read_csv('./letter_data/letter-recognition.txt')\n",
        "\n",
        "training_points = np.array(letters[:15000].drop(['letter'], 1))\n",
        "training_labels = np.array(letters[:15000]['letter'])\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(training_points,training_labels)\n",
        "\n",
        "\n",
        "test_points = np.array(letters[1500:].drop(['letter'], 1))\n",
        "test_labels = np.array(letters[1500:]['letter'])\n",
        "\n",
        "accuracy = clf.score(test_points, test_labels)\n",
        "\n",
        "print(float(accuracy))\n",
        "\n",
        "expected = test_labels\n",
        "predicted = clf.predict(test_points)\n",
        "\n",
        "# summarize the fit of the model\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "print(metrics.confusion_matrix(expected, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import tree, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read and preprocess data\n",
        "letters = pd.read_csv('./letter_data/letter-recognition.txt')\n",
        "X = letters.drop(['letter'], axis=1)\n",
        "y = letters['letter']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define fitness function\n",
        "def evaluate(max_depth, min_samples_split, X_train, y_train, X_test, y_test):\n",
        "    clf = tree.DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
        "    clf.fit(X_train, y_train)\n",
        "    accuracy = clf.score(X_test, y_test)\n",
        "    return accuracy\n",
        "\n",
        "# Evolutionary algorithm parameters\n",
        "POP_SIZE = 10\n",
        "NUM_GENERATIONS = 100\n",
        "MUTATION_RATE = 0.2\n",
        "\n",
        "# Initialize population\n",
        "population = np.random.randint(2, 20, size=(POP_SIZE, 2))\n",
        "\n",
        "# Main loop\n",
        "for gen in range(NUM_GENERATIONS):\n",
        "    # Evaluate fitness\n",
        "    fitnesses = [evaluate(max_depth, min_samples_split, X_train, y_train, X_test, y_test) for max_depth, min_samples_split in population]\n",
        "\n",
        "    # Select top individuals\n",
        "    sorted_indices = np.argsort(fitnesses)[::-1]\n",
        "    top_individuals = population[sorted_indices[:2]]\n",
        "\n",
        "    # Generate new population\n",
        "    new_population = np.zeros_like(population)\n",
        "    for i in range(POP_SIZE):\n",
        "        parent1, parent2 = np.random.choice(2, 2, replace=False)\n",
        "        offspring = np.array([top_individuals[parent1, 0], top_individuals[parent2, 1]])\n",
        "        \n",
        "        # Mutation\n",
        "        if np.random.rand() < MUTATION_RATE:\n",
        "            mutation_idx = np.random.randint(2)\n",
        "            mutation_value = np.random.randint(-2, 3)\n",
        "            offspring[mutation_idx] += mutation_value\n",
        "            offspring[mutation_idx] = max(2, offspring[mutation_idx])\n",
        "\n",
        "        new_population[i] = offspring\n",
        "\n",
        "    population = new_population\n",
        "    best_individual = top_individuals[0]\n",
        "    print(f\"Generation {gen + 1}: Best fitness = {max(fitnesses)}, max_depth = {best_individual[0]}, min_samples_split = {best_individual[1]}\")\n",
        "\n",
        "# Train and evaluate the best decision tree\n",
        "best_max_depth, best_min_samples_split = best_individual\n",
        "best_clf = tree.DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "accuracy = best_clf.score(X_test, y_test)\n",
        "print(f\"Final accuracy: {accuracy}\")\n",
        "\n",
        "expected = y_test\n",
        "predicted = best_clf.predict(X_test)\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "print(metrics.confusion_matrix(expected, predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuZ8GuDA5clF",
        "outputId": "687d3087-8a81-4ceb-8d4e-a46ae68435b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best fitness = 0.8616666666666667, max_depth = 19, min_samples_split = 6\n",
            "Generation 2: Best fitness = 0.8616666666666667, max_depth = 19, min_samples_split = 6\n",
            "Generation 3: Best fitness = 0.8631666666666666, max_depth = 19, min_samples_split = 6\n",
            "Generation 4: Best fitness = 0.8628333333333333, max_depth = 19, min_samples_split = 6\n",
            "Generation 5: Best fitness = 0.8636666666666667, max_depth = 19, min_samples_split = 6\n",
            "Generation 6: Best fitness = 0.8623333333333333, max_depth = 19, min_samples_split = 6\n",
            "Generation 7: Best fitness = 0.8631666666666666, max_depth = 19, min_samples_split = 6\n",
            "Generation 8: Best fitness = 0.8623333333333333, max_depth = 19, min_samples_split = 6\n",
            "Generation 9: Best fitness = 0.862, max_depth = 19, min_samples_split = 6\n",
            "Generation 10: Best fitness = 0.8635, max_depth = 19, min_samples_split = 6\n",
            "Generation 11: Best fitness = 0.8663333333333333, max_depth = 19, min_samples_split = 5\n",
            "Generation 12: Best fitness = 0.8665, max_depth = 19, min_samples_split = 3\n",
            "Generation 13: Best fitness = 0.8688333333333333, max_depth = 19, min_samples_split = 3\n",
            "Generation 14: Best fitness = 0.8701666666666666, max_depth = 19, min_samples_split = 3\n",
            "Generation 15: Best fitness = 0.8696666666666667, max_depth = 19, min_samples_split = 3\n",
            "Generation 16: Best fitness = 0.87, max_depth = 19, min_samples_split = 3\n",
            "Generation 17: Best fitness = 0.8688333333333333, max_depth = 19, min_samples_split = 3\n",
            "Generation 18: Best fitness = 0.8698333333333333, max_depth = 19, min_samples_split = 3\n",
            "Generation 19: Best fitness = 0.8695, max_depth = 19, min_samples_split = 3\n",
            "Generation 20: Best fitness = 0.8705, max_depth = 20, min_samples_split = 3\n",
            "Generation 21: Best fitness = 0.8703333333333333, max_depth = 19, min_samples_split = 3\n",
            "Generation 22: Best fitness = 0.8713333333333333, max_depth = 19, min_samples_split = 2\n",
            "Generation 23: Best fitness = 0.8713333333333333, max_depth = 19, min_samples_split = 2\n",
            "Generation 24: Best fitness = 0.8738333333333334, max_depth = 19, min_samples_split = 2\n",
            "Generation 25: Best fitness = 0.876, max_depth = 21, min_samples_split = 2\n",
            "Generation 26: Best fitness = 0.8753333333333333, max_depth = 21, min_samples_split = 2\n",
            "Generation 27: Best fitness = 0.8775, max_depth = 21, min_samples_split = 2\n",
            "Generation 28: Best fitness = 0.876, max_depth = 21, min_samples_split = 2\n",
            "Generation 29: Best fitness = 0.8755, max_depth = 21, min_samples_split = 2\n",
            "Generation 30: Best fitness = 0.8753333333333333, max_depth = 21, min_samples_split = 2\n",
            "Generation 31: Best fitness = 0.876, max_depth = 21, min_samples_split = 2\n",
            "Generation 32: Best fitness = 0.8763333333333333, max_depth = 21, min_samples_split = 2\n",
            "Generation 33: Best fitness = 0.8736666666666667, max_depth = 21, min_samples_split = 2\n",
            "Generation 34: Best fitness = 0.875, max_depth = 21, min_samples_split = 2\n",
            "Generation 35: Best fitness = 0.8763333333333333, max_depth = 21, min_samples_split = 2\n",
            "Generation 36: Best fitness = 0.8773333333333333, max_depth = 23, min_samples_split = 2\n",
            "Generation 37: Best fitness = 0.8785, max_depth = 23, min_samples_split = 2\n",
            "Generation 38: Best fitness = 0.878, max_depth = 23, min_samples_split = 2\n",
            "Generation 39: Best fitness = 0.8758333333333334, max_depth = 23, min_samples_split = 2\n",
            "Generation 40: Best fitness = 0.8768333333333334, max_depth = 22, min_samples_split = 2\n",
            "Generation 41: Best fitness = 0.8765, max_depth = 23, min_samples_split = 2\n",
            "Generation 42: Best fitness = 0.8778333333333334, max_depth = 23, min_samples_split = 2\n",
            "Generation 43: Best fitness = 0.877, max_depth = 23, min_samples_split = 2\n",
            "Generation 44: Best fitness = 0.8768333333333334, max_depth = 23, min_samples_split = 2\n",
            "Generation 45: Best fitness = 0.8775, max_depth = 23, min_samples_split = 2\n",
            "Generation 46: Best fitness = 0.8803333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 47: Best fitness = 0.8768333333333334, max_depth = 24, min_samples_split = 2\n",
            "Generation 48: Best fitness = 0.8778333333333334, max_depth = 24, min_samples_split = 2\n",
            "Generation 49: Best fitness = 0.8813333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 50: Best fitness = 0.8796666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 51: Best fitness = 0.8775, max_depth = 24, min_samples_split = 2\n",
            "Generation 52: Best fitness = 0.8781666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 53: Best fitness = 0.8778333333333334, max_depth = 24, min_samples_split = 2\n",
            "Generation 54: Best fitness = 0.878, max_depth = 24, min_samples_split = 2\n",
            "Generation 55: Best fitness = 0.8778333333333334, max_depth = 24, min_samples_split = 2\n",
            "Generation 56: Best fitness = 0.8763333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 57: Best fitness = 0.8775, max_depth = 24, min_samples_split = 2\n",
            "Generation 58: Best fitness = 0.8783333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 59: Best fitness = 0.8763333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 60: Best fitness = 0.8781666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 61: Best fitness = 0.8775, max_depth = 24, min_samples_split = 2\n",
            "Generation 62: Best fitness = 0.8771666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 63: Best fitness = 0.877, max_depth = 25, min_samples_split = 2\n",
            "Generation 64: Best fitness = 0.8795, max_depth = 25, min_samples_split = 2\n",
            "Generation 65: Best fitness = 0.8803333333333333, max_depth = 25, min_samples_split = 2\n",
            "Generation 66: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 67: Best fitness = 0.8773333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 68: Best fitness = 0.8771666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 69: Best fitness = 0.8778333333333334, max_depth = 25, min_samples_split = 2\n",
            "Generation 70: Best fitness = 0.8786666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 71: Best fitness = 0.8798333333333334, max_depth = 25, min_samples_split = 2\n",
            "Generation 72: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 73: Best fitness = 0.8781666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 74: Best fitness = 0.8778333333333334, max_depth = 25, min_samples_split = 2\n",
            "Generation 75: Best fitness = 0.8781666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 76: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 77: Best fitness = 0.8768333333333334, max_depth = 25, min_samples_split = 2\n",
            "Generation 78: Best fitness = 0.879, max_depth = 25, min_samples_split = 2\n",
            "Generation 79: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 80: Best fitness = 0.8801666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 81: Best fitness = 0.8783333333333333, max_depth = 25, min_samples_split = 2\n",
            "Generation 82: Best fitness = 0.876, max_depth = 23, min_samples_split = 2\n",
            "Generation 83: Best fitness = 0.8788333333333334, max_depth = 23, min_samples_split = 2\n",
            "Generation 84: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 85: Best fitness = 0.8806666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 86: Best fitness = 0.8775, max_depth = 25, min_samples_split = 2\n",
            "Generation 87: Best fitness = 0.8775, max_depth = 25, min_samples_split = 2\n",
            "Generation 88: Best fitness = 0.8793333333333333, max_depth = 25, min_samples_split = 2\n",
            "Generation 89: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 90: Best fitness = 0.8785, max_depth = 25, min_samples_split = 2\n",
            "Generation 91: Best fitness = 0.8776666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 92: Best fitness = 0.8801666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 93: Best fitness = 0.8793333333333333, max_depth = 25, min_samples_split = 2\n",
            "Generation 94: Best fitness = 0.8785, max_depth = 25, min_samples_split = 2\n",
            "Generation 95: Best fitness = 0.878, max_depth = 25, min_samples_split = 2\n",
            "Generation 96: Best fitness = 0.8783333333333333, max_depth = 25, min_samples_split = 2\n",
            "Generation 97: Best fitness = 0.8766666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 98: Best fitness = 0.878, max_depth = 25, min_samples_split = 2\n",
            "Generation 99: Best fitness = 0.8781666666666667, max_depth = 25, min_samples_split = 2\n",
            "Generation 100: Best fitness = 0.8786666666666667, max_depth = 26, min_samples_split = 2\n",
            "Final accuracy: 0.875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.93      0.95      0.94       232\n",
            "           B       0.80      0.80      0.80       229\n",
            "           C       0.89      0.86      0.88       201\n",
            "           D       0.82      0.87      0.84       250\n",
            "           E       0.83      0.87      0.85       238\n",
            "           F       0.82      0.88      0.85       211\n",
            "           G       0.82      0.83      0.82       230\n",
            "           H       0.75      0.75      0.75       218\n",
            "           I       0.88      0.89      0.88       221\n",
            "           J       0.93      0.85      0.89       228\n",
            "           K       0.81      0.82      0.82       188\n",
            "           L       0.92      0.94      0.93       231\n",
            "           M       0.92      0.91      0.92       252\n",
            "           N       0.91      0.86      0.88       231\n",
            "           O       0.81      0.84      0.83       218\n",
            "           P       0.90      0.88      0.89       248\n",
            "           Q       0.86      0.81      0.84       253\n",
            "           R       0.86      0.83      0.84       234\n",
            "           S       0.85      0.90      0.88       235\n",
            "           T       0.89      0.92      0.91       232\n",
            "           U       0.91      0.93      0.92       261\n",
            "           V       0.93      0.90      0.92       237\n",
            "           W       0.93      0.95      0.94       213\n",
            "           X       0.93      0.89      0.91       245\n",
            "           Y       0.91      0.92      0.91       251\n",
            "           Z       0.91      0.90      0.90       213\n",
            "\n",
            "    accuracy                           0.88      6000\n",
            "   macro avg       0.87      0.87      0.87      6000\n",
            "weighted avg       0.88      0.88      0.88      6000\n",
            "\n",
            "[[220   0   1   3   0   0   0   0   0   1   1   1   1   0   1   0   1   0\n",
            "    1   0   1   0   0   0   0   0]\n",
            " [  2 183   0   2   2   4   5   1   0   1   0   0   4   0   4   4   0   5\n",
            "    3   1   0   4   0   4   0   0]\n",
            " [  0   1 173   0   6   4  10   2   0   0   1   0   0   0   0   0   1   1\n",
            "    0   0   2   0   0   0   0   0]\n",
            " [  0   2   0 217   0   4   2   7   1   0   2   0   0   5   3   1   0   2\n",
            "    1   1   0   0   0   0   0   2]\n",
            " [  0   1   5   0 207   2   3   0   4   0   2   0   0   0   0   0   6   2\n",
            "    1   1   1   0   0   1   0   2]\n",
            " [  0   3   1   0   1 186   1   0   2   1   0   0   0   0   0   4   1   1\n",
            "    1   6   1   1   0   0   1   0]\n",
            " [  1   5   3   3   4   0 190   1   0   2   0   2   0   0   7   0   5   1\n",
            "    1   0   0   1   1   1   0   2]\n",
            " [  0   7   0   9   1   2   1 163   0   1  15   0   0   0   2   4   0   4\n",
            "    6   0   0   0   1   1   0   1]\n",
            " [  1   1   0   3   0   0   0   0 196   5   0   1   0   2   0   2   1   0\n",
            "    4   2   0   0   0   1   0   2]\n",
            " [  0   4   0   1   1   2   0   2   9 193   1   2   0   0   0   1   2   0\n",
            "    4   0   1   0   0   2   1   2]\n",
            " [  0   1   1   2   6   0   2   4   2   0 155   2   0   0   0   0   1   6\n",
            "    0   1   2   0   0   3   0   0]\n",
            " [  1   2   0   2   1   1   3   0   0   0   0 217   0   0   1   1   1   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  1   0   1   1   1   0   0   2   0   0   1   2 229   3   1   0   0   1\n",
            "    0   0   5   0   3   0   1   0]\n",
            " [  2   2   1   5   0   1   0   3   0   0   0   1   4 198   1   2   0   1\n",
            "    0   0   5   0   2   0   3   0]\n",
            " [  0   0   2   6   1   1   3   4   0   0   3   1   0   2 183   2   5   2\n",
            "    0   0   2   1   0   0   0   0]\n",
            " [  2   1   0   0   0  14   0   0   3   0   0   1   0   0   1 218   0   1\n",
            "    1   0   0   1   3   0   2   0]\n",
            " [  0   2   2   5   9   1   3   1   0   2   1   1   0   0  13   1 205   0\n",
            "    1   0   0   1   1   0   2   2]\n",
            " [  0   4   0   3   2   0   4  11   1   1   5   1   0   2   1   0   1 194\n",
            "    1   0   0   1   1   1   0   0]\n",
            " [  0   1   0   0   1   0   2   4   2   0   0   0   2   1   1   0   0   2\n",
            "  212   0   0   0   0   2   0   5]\n",
            " [  1   0   0   0   0   2   0   1   0   0   1   1   0   0   0   0   1   1\n",
            "    1 213   0   2   0   1   7   0]\n",
            " [  1   0   3   0   0   0   2   2   0   0   0   0   2   2   2   0   1   0\n",
            "    1   0 242   1   2   0   0   0]\n",
            " [  0   3   0   1   0   2   0   2   0   0   0   0   2   1   1   1   0   0\n",
            "    0   6   0 213   2   0   3   0]\n",
            " [  0   1   0   0   0   0   0   2   0   0   0   0   2   0   2   0   0   1\n",
            "    0   0   0   1 202   0   2   0]\n",
            " [  2   3   1   1   4   0   0   1   0   0   4   1   0   0   0   0   3   0\n",
            "    2   1   1   0   0 219   1   1]\n",
            " [  1   0   0   0   0   1   0   2   2   0   0   0   2   1   0   1   1   0\n",
            "    1   6   2   1   0   0 230   0]\n",
            " [  1   1   0   2   3   0   0   2   1   1   0   1   0   0   1   0   1   1\n",
            "    6   0   0   0   0   0   0 192]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import tree, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read and preprocess data\n",
        "letters = pd.read_csv('./letter_data/letter-recognition.txt')\n",
        "X = letters.drop(['letter'], axis=1)\n",
        "y = letters['letter']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define fitness function\n",
        "def evaluate(clf, X_test, y_test):\n",
        "    accuracy = clf.score(X_test, y_test)\n",
        "    return accuracy\n",
        "\n",
        "# Create decision tree classifier\n",
        "def create_classifier(max_depth, min_samples_split):\n",
        "    clf = tree.DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "# Evolutionary algorithm parameters\n",
        "POP_SIZE = 10\n",
        "NUM_GENERATIONS = 50\n",
        "MUTATION_RATE = 0.2\n",
        "\n",
        "# Initialize population\n",
        "population = [create_classifier(np.random.randint(2, 20), np.random.randint(2, 20)) for _ in range(POP_SIZE)]\n",
        "\n",
        "# Main loop\n",
        "for gen in range(NUM_GENERATIONS):\n",
        "    # Evaluate fitness\n",
        "    fitnesses = [evaluate(clf, X_test, y_test) for clf in population]\n",
        "\n",
        "    # Select top individuals\n",
        "    sorted_indices = np.argsort(fitnesses)[::-1]\n",
        "    top_individuals = [population[i] for i in sorted_indices[:2]]\n",
        "\n",
        "    # Generate new population\n",
        "    new_population = []\n",
        "    for i in range(POP_SIZE):\n",
        "        parent1, parent2 = np.random.choice(2, 2, replace=False)\n",
        "        offspring_max_depth = top_individuals[parent1].get_params()['max_depth']\n",
        "        offspring_min_samples_split = top_individuals[parent2].get_params()['min_samples_split']\n",
        "\n",
        "        # Mutation\n",
        "        if np.random.rand() < MUTATION_RATE:\n",
        "            mutation_idx = np.random.randint(2)\n",
        "            mutation_value = np.random.randint(-2, 3)\n",
        "            if mutation_idx == 0:\n",
        "                offspring_max_depth += mutation_value\n",
        "                offspring_max_depth = max(2, offspring_max_depth)\n",
        "            else:\n",
        "                offspring_min_samples_split += mutation_value\n",
        "                offspring_min_samples_split = max(2, offspring_min_samples_split)\n",
        "\n",
        "        offspring = create_classifier(offspring_max_depth, offspring_min_samples_split)\n",
        "        new_population.append(offspring)\n",
        "\n",
        "    population = new_population\n",
        "    best_individual = top_individuals[0]\n",
        "    best_hyperparams = best_individual.get_params()\n",
        "    print(f\"Generation {gen + 1}: Best fitness = {max(fitnesses)}, max_depth = {best_hyperparams['max_depth']}, min_samples_split = {best_hyperparams['min_samples_split']}\")\n",
        "\n",
        "# Evaluate the best decision tree\n",
        "accuracy = evaluate(best_individual, X_test, y_test)\n",
        "print(f\"Final accuracy: {accuracy}\")\n",
        "\n",
        "expected = y_test\n",
        "predicted = best_individual.predict(X_test)\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "print(metrics.confusion_matrix(expected, predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLM2vLNl_TtW",
        "outputId": "494d7ad2-0fc7-4844-9605-2ede24b44b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best fitness = 0.801, max_depth = 14, min_samples_split = 14\n",
            "Generation 2: Best fitness = 0.8045, max_depth = 14, min_samples_split = 12\n",
            "Generation 3: Best fitness = 0.824, max_depth = 16, min_samples_split = 12\n",
            "Generation 4: Best fitness = 0.8306666666666667, max_depth = 16, min_samples_split = 10\n",
            "Generation 5: Best fitness = 0.8391666666666666, max_depth = 17, min_samples_split = 10\n",
            "Generation 6: Best fitness = 0.8405, max_depth = 17, min_samples_split = 10\n",
            "Generation 7: Best fitness = 0.8456666666666667, max_depth = 17, min_samples_split = 8\n",
            "Generation 8: Best fitness = 0.8535, max_depth = 19, min_samples_split = 8\n",
            "Generation 9: Best fitness = 0.8581666666666666, max_depth = 21, min_samples_split = 8\n",
            "Generation 10: Best fitness = 0.8595, max_depth = 21, min_samples_split = 8\n",
            "Generation 11: Best fitness = 0.8595, max_depth = 21, min_samples_split = 8\n",
            "Generation 12: Best fitness = 0.8595, max_depth = 22, min_samples_split = 8\n",
            "Generation 13: Best fitness = 0.8595, max_depth = 22, min_samples_split = 8\n",
            "Generation 14: Best fitness = 0.8591666666666666, max_depth = 22, min_samples_split = 8\n",
            "Generation 15: Best fitness = 0.8598333333333333, max_depth = 22, min_samples_split = 8\n",
            "Generation 16: Best fitness = 0.8605, max_depth = 22, min_samples_split = 8\n",
            "Generation 17: Best fitness = 0.8608333333333333, max_depth = 22, min_samples_split = 8\n",
            "Generation 18: Best fitness = 0.8605, max_depth = 22, min_samples_split = 8\n",
            "Generation 19: Best fitness = 0.859, max_depth = 22, min_samples_split = 8\n",
            "Generation 20: Best fitness = 0.86, max_depth = 22, min_samples_split = 8\n",
            "Generation 21: Best fitness = 0.8605, max_depth = 22, min_samples_split = 8\n",
            "Generation 22: Best fitness = 0.8615, max_depth = 22, min_samples_split = 8\n",
            "Generation 23: Best fitness = 0.86, max_depth = 24, min_samples_split = 8\n",
            "Generation 24: Best fitness = 0.8603333333333333, max_depth = 22, min_samples_split = 8\n",
            "Generation 25: Best fitness = 0.8626666666666667, max_depth = 24, min_samples_split = 6\n",
            "Generation 26: Best fitness = 0.8656666666666667, max_depth = 24, min_samples_split = 6\n",
            "Generation 27: Best fitness = 0.869, max_depth = 24, min_samples_split = 4\n",
            "Generation 28: Best fitness = 0.8745, max_depth = 24, min_samples_split = 2\n",
            "Generation 29: Best fitness = 0.8761666666666666, max_depth = 24, min_samples_split = 2\n",
            "Generation 30: Best fitness = 0.8791666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 31: Best fitness = 0.8816666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 32: Best fitness = 0.878, max_depth = 24, min_samples_split = 2\n",
            "Generation 33: Best fitness = 0.8783333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 34: Best fitness = 0.8781666666666667, max_depth = 22, min_samples_split = 2\n",
            "Generation 35: Best fitness = 0.8786666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 36: Best fitness = 0.8775, max_depth = 24, min_samples_split = 2\n",
            "Generation 37: Best fitness = 0.8815, max_depth = 24, min_samples_split = 2\n",
            "Generation 38: Best fitness = 0.8795, max_depth = 24, min_samples_split = 2\n",
            "Generation 39: Best fitness = 0.8803333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 40: Best fitness = 0.8793333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 41: Best fitness = 0.8791666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 42: Best fitness = 0.8761666666666666, max_depth = 24, min_samples_split = 2\n",
            "Generation 43: Best fitness = 0.8778333333333334, max_depth = 24, min_samples_split = 2\n",
            "Generation 44: Best fitness = 0.878, max_depth = 24, min_samples_split = 2\n",
            "Generation 45: Best fitness = 0.8781666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 46: Best fitness = 0.8791666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 47: Best fitness = 0.8773333333333333, max_depth = 24, min_samples_split = 2\n",
            "Generation 48: Best fitness = 0.878, max_depth = 24, min_samples_split = 2\n",
            "Generation 49: Best fitness = 0.8781666666666667, max_depth = 24, min_samples_split = 2\n",
            "Generation 50: Best fitness = 0.8778333333333334, max_depth = 24, min_samples_split = 2\n",
            "Final accuracy: 0.8778333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.91      0.97      0.94       232\n",
            "           B       0.81      0.83      0.82       229\n",
            "           C       0.91      0.86      0.88       201\n",
            "           D       0.84      0.89      0.86       250\n",
            "           E       0.83      0.88      0.85       238\n",
            "           F       0.83      0.87      0.85       211\n",
            "           G       0.82      0.84      0.83       230\n",
            "           H       0.75      0.78      0.77       218\n",
            "           I       0.90      0.87      0.89       221\n",
            "           J       0.94      0.86      0.90       228\n",
            "           K       0.82      0.83      0.83       188\n",
            "           L       0.91      0.94      0.92       231\n",
            "           M       0.93      0.92      0.93       252\n",
            "           N       0.91      0.87      0.89       231\n",
            "           O       0.84      0.82      0.83       218\n",
            "           P       0.91      0.88      0.90       248\n",
            "           Q       0.86      0.80      0.83       253\n",
            "           R       0.85      0.82      0.83       234\n",
            "           S       0.87      0.89      0.88       235\n",
            "           T       0.88      0.91      0.90       232\n",
            "           U       0.89      0.92      0.91       261\n",
            "           V       0.93      0.91      0.92       237\n",
            "           W       0.94      0.92      0.93       213\n",
            "           X       0.91      0.90      0.91       245\n",
            "           Y       0.91      0.91      0.91       251\n",
            "           Z       0.91      0.91      0.91       213\n",
            "\n",
            "    accuracy                           0.88      6000\n",
            "   macro avg       0.88      0.88      0.88      6000\n",
            "weighted avg       0.88      0.88      0.88      6000\n",
            "\n",
            "[[224   0   0   3   0   0   0   0   0   1   0   2   1   0   0   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  2 190   0   3   2   1   6   2   1   0   0   1   1   0   1   2   1   4\n",
            "    2   2   0   3   0   5   0   0]\n",
            " [  0   0 173   0   5   4  11   1   0   0   0   0   0   0   0   0   1   1\n",
            "    1   0   4   0   0   0   0   0]\n",
            " [  0   4   0 222   0   4   1   6   2   0   1   0   0   2   2   1   0   1\n",
            "    2   1   0   0   0   0   0   1]\n",
            " [  0   1   4   0 209   1   3   0   1   0   2   0   0   0   1   0   6   1\n",
            "    0   1   1   0   0   5   0   2]\n",
            " [  0   3   1   0   1 184   1   0   2   1   0   0   1   1   0   5   1   1\n",
            "    0   8   0   0   0   0   1   0]\n",
            " [  1   3   1   3   4   0 193   1   0   1   0   4   0   0   5   0   4   2\n",
            "    2   1   2   1   1   1   0   0]\n",
            " [  0   5   0   5   1   3   1 170   0   1  14   0   0   1   2   3   1   5\n",
            "    4   0   1   0   0   0   0   1]\n",
            " [  3   2   0   2   0   0   0   0 193   6   0   1   0   2   0   2   2   1\n",
            "    2   2   0   0   0   1   0   2]\n",
            " [  3   2   0   3   1   1   0   1   6 196   1   0   0   0   0   1   1   0\n",
            "    4   0   1   0   0   1   3   3]\n",
            " [  0   1   1   1   4   0   1   6   0   0 156   1   0   0   0   0   1   9\n",
            "    0   2   2   0   0   3   0   0]\n",
            " [  1   1   1   0   1   0   4   0   0   0   1 216   0   0   1   0   2   0\n",
            "    0   1   0   0   0   0   0   2]\n",
            " [  1   0   0   0   1   0   0   3   0   0   0   2 233   3   1   1   0   0\n",
            "    1   0   4   0   2   0   0   0]\n",
            " [  2   1   1   6   0   1   0   3   0   0   0   1   4 202   1   1   0   1\n",
            "    0   0   5   0   1   0   1   0]\n",
            " [  0   1   1   8   0   0   5   4   0   0   1   0   0   1 179   1   6   2\n",
            "    1   0   3   2   2   0   1   0]\n",
            " [  1   1   0   0   1  14   0   1   3   0   0   3   0   0   0 218   0   1\n",
            "    0   0   0   0   3   0   2   0]\n",
            " [  0   3   3   5  10   1   4   2   0   1   1   0   0   0  13   0 203   0\n",
            "    0   0   1   2   0   0   2   2]\n",
            " [  1   6   0   2   2   0   2  13   1   1   6   2   0   1   2   0   0 191\n",
            "    0   0   0   0   1   2   1   0]\n",
            " [  1   1   0   0   1   0   1   4   3   0   2   2   0   0   1   0   1   2\n",
            "  210   0   0   0   0   2   0   4]\n",
            " [  0   0   0   0   0   3   0   1   0   1   0   1   0   0   0   1   2   1\n",
            "    2 212   0   1   0   1   6   0]\n",
            " [  1   0   4   0   0   0   1   3   0   0   0   0   2   2   2   0   1   0\n",
            "    2   0 240   1   2   0   0   0]\n",
            " [  0   3   0   0   0   2   0   1   0   0   0   0   2   2   0   2   0   0\n",
            "    0   5   1 216   1   0   2   0]\n",
            " [  0   2   0   0   0   1   0   0   0   0   0   0   3   0   2   0   0   1\n",
            "    0   0   2   4 196   0   2   0]\n",
            " [  2   3   0   1   3   1   0   1   1   0   5   0   2   1   0   0   0   1\n",
            "    1   1   0   0   0 220   0   2]\n",
            " [  1   0   0   0   2   1   0   3   0   0   0   0   2   3   0   1   1   0\n",
            "    0   5   2   2   0   0 228   0]\n",
            " [  1   3   0   1   3   0   0   0   1   0   0   1   0   0   1   0   1   0\n",
            "    7   0   0   0   0   0   1 193]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "\n",
        "letters = pd.read_csv('letter-recognition.txt')\n",
        "\n",
        "training_points = np.array(letters[:15000].drop(['letter'], 1))\n",
        "training_labels = np.array(letters[:15000]['letter'])\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(training_points, training_labels) \n",
        "\n",
        "\n",
        "test_points = np.array(letters[15000:].drop(['letter'], 1))\n",
        "test_labels = np.array(letters[15000:]['letter'])\n",
        "\n",
        "expected = test_labels\n",
        "predicted = clf.predict(test_points)\n",
        "\n",
        "accuracy = clf.score(test_points, test_labels)\n",
        "\n",
        "print(float(accuracy))\n",
        "\n",
        "# summarize the fit of the model\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "print(metrics.confusion_matrix(expected, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWQRDC0xCnzf",
        "outputId": "f4f17c79-dee0-4cfa-fd3f-799e00ec2ae1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-391b521225eb>:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  training_points = np.array(letters[:15000].drop(['letter'], 1))\n",
            "<ipython-input-2-391b521225eb>:15: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  test_points = np.array(letters[15000:].drop(['letter'], 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.916\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      0.96      0.97       206\n",
            "           B       0.81      0.94      0.87       173\n",
            "           C       0.94      0.89      0.92       171\n",
            "           D       0.83      0.94      0.88       216\n",
            "           E       0.85      0.90      0.87       191\n",
            "           F       0.88      0.94      0.91       194\n",
            "           G       0.86      0.90      0.88       208\n",
            "           H       0.86      0.81      0.83       178\n",
            "           I       0.96      0.91      0.94       205\n",
            "           J       0.95      0.91      0.93       183\n",
            "           K       0.89      0.90      0.90       177\n",
            "           L       0.99      0.88      0.93       205\n",
            "           M       0.93      0.96      0.95       187\n",
            "           N       0.96      0.90      0.93       198\n",
            "           O       0.87      0.90      0.88       181\n",
            "           P       0.98      0.84      0.90       207\n",
            "           Q       0.94      0.94      0.94       217\n",
            "           R       0.83      0.90      0.86       208\n",
            "           S       0.95      0.93      0.94       198\n",
            "           T       0.98      0.92      0.95       184\n",
            "           U       0.99      0.95      0.97       215\n",
            "           V       0.95      0.91      0.93       168\n",
            "           W       0.88      0.96      0.92       167\n",
            "           X       0.93      0.95      0.94       186\n",
            "           Y       0.95      0.93      0.94       183\n",
            "           Z       0.95      0.95      0.95       194\n",
            "\n",
            "    accuracy                           0.92      5000\n",
            "   macro avg       0.92      0.92      0.92      5000\n",
            "weighted avg       0.92      0.92      0.92      5000\n",
            "\n",
            "[[198   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   1\n",
            "    0   0   1   0   0   0   4   0]\n",
            " [  0 162   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   7\n",
            "    2   0   0   0   0   1   0   0]\n",
            " [  0   0 152   0   7   0   4   0   0   0   4   0   1   0   2   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   6   0 202   0   0   0   3   0   0   0   0   1   2   1   0   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   2   2   0 171   0  10   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1   0   5]\n",
            " [  0   0   0   1   2 182   2   2   0   0   0   0   0   2   0   2   0   0\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  0   1   1   3   1   3 187   1   0   0   1   0   1   0   2   0   2   2\n",
            "    0   0   0   1   2   0   0   0]\n",
            " [  0   3   1  11   0   1   2 144   0   0   5   0   1   0   0   0   2   5\n",
            "    0   0   1   1   0   0   1   0]\n",
            " [  0   0   2   2   0   5   0   0 187   5   0   0   0   0   0   1   0   0\n",
            "    1   0   0   0   0   0   0   2]\n",
            " [  0   0   0   3   2   0   0   1   5 166   0   0   0   0   1   0   0   0\n",
            "    3   0   0   0   0   0   0   2]\n",
            " [  0   0   0   1   1   0   0   1   0   0 160   0   0   0   0   0   0  11\n",
            "    0   0   0   0   0   3   0   0]\n",
            " [  0   1   3   0   7   0   2   1   0   0   0 180   0   0   0   0   1   2\n",
            "    3   0   0   0   0   5   0   0]\n",
            " [  0   2   0   0   0   0   3   1   0   0   0   0 180   0   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   1   0   1   0   0   0   3   0   0   1   0   2 179   7   0   0   3\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  1   0   0   1   0   0   1   0   0   0   0   0   0   0 163   0   5   2\n",
            "    0   0   0   0   8   0   0   0]\n",
            " [  0   2   0   4   0  13   3   1   0   0   0   0   0   0   3 174   3   1\n",
            "    0   0   0   0   0   0   3   0]\n",
            " [  2   2   0   1   2   0   1   0   0   0   0   0   0   0   6   0 203   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   5   0   4   0   0   0   5   0   0   5   0   0   2   0   0   0 187\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  1   3   0   0   4   2   0   0   0   0   0   1   0   0   0   0   0   0\n",
            "  184   1   0   0   0   1   0   1]\n",
            " [  1   1   0   1   1   0   2   3   0   0   1   0   0   0   0   0   0   2\n",
            "    0 170   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0   3   0   0   0\n",
            "    0   0 204   1   4   0   0   0]\n",
            " [  0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
            "    0   0   0 153   7   0   0   0]\n",
            " [  1   1   0   0   0   0   0   0   0   0   0   0   3   1   0   0   0   0\n",
            "    0   0   0   0 161   0   0   0]\n",
            " [  0   1   0   3   1   0   0   0   2   1   2   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 176   0   0]\n",
            " [  0   0   0   3   0   1   0   1   0   0   0   0   1   0   0   1   0   0\n",
            "    0   1   0   4   0   1 170   0]\n",
            " [  0   0   0   0   2   0   0   0   0   3   0   1   0   0   0   0   1   0\n",
            "    1   0   0   0   0   1   0 185]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# naive bayes\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "letters = pd.read_csv('letter-recognition.txt')\n",
        "\n",
        "training_points = np.array(letters[:15000].drop(['letter'], 1))\n",
        "training_labels = np.array(letters[:15000]['letter'])\n",
        "\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(training_points, training_labels)\n",
        "\n",
        "\n",
        "test_points = np.array(letters[15000:].drop(['letter'], 1))\n",
        "test_labels = np.array(letters[15000:]['letter'])\n",
        "# predicts = clf.predict(test_points)\n",
        "\n",
        "accuracy = clf.score(test_points, test_labels)\n",
        "\n",
        "print(float(accuracy))\n",
        "\n",
        "expected = test_labels\n",
        "predicted = clf.predict(test_points)\n",
        "\n",
        "# summarize the fit of the model\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "print(metrics.confusion_matrix(expected, predicted))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABPt-fyLDWsO",
        "outputId": "be7bea90-3168-47c7-b4d5-7de64f27f22c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ce5acfcd2279>:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  training_points = np.array(letters[:15000].drop(['letter'], 1))\n",
            "<ipython-input-3-ce5acfcd2279>:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  test_points = np.array(letters[15000:].drop(['letter'], 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.633\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.85      0.85      0.85       206\n",
            "           B       0.45      0.70      0.55       173\n",
            "           C       0.74      0.74      0.74       171\n",
            "           D       0.57      0.69      0.62       216\n",
            "           E       0.67      0.39      0.49       191\n",
            "           F       0.69      0.73      0.71       194\n",
            "           G       0.57      0.54      0.55       208\n",
            "           H       0.50      0.30      0.37       178\n",
            "           I       0.54      0.75      0.63       205\n",
            "           J       0.76      0.75      0.75       183\n",
            "           K       0.43      0.45      0.44       177\n",
            "           L       0.95      0.76      0.84       205\n",
            "           M       0.67      0.91      0.78       187\n",
            "           N       0.86      0.60      0.71       198\n",
            "           O       0.46      0.68      0.55       181\n",
            "           P       0.86      0.72      0.79       207\n",
            "           Q       0.59      0.53      0.56       217\n",
            "           R       0.56      0.64      0.60       208\n",
            "           S       0.32      0.27      0.30       198\n",
            "           T       0.72      0.72      0.72       184\n",
            "           U       0.88      0.70      0.78       215\n",
            "           V       0.63      0.77      0.69       168\n",
            "           W       0.65      0.78      0.71       167\n",
            "           X       0.45      0.54      0.49       186\n",
            "           Y       0.69      0.35      0.46       183\n",
            "           Z       0.77      0.59      0.67       194\n",
            "\n",
            "    accuracy                           0.63      5000\n",
            "   macro avg       0.65      0.63      0.63      5000\n",
            "weighted avg       0.65      0.63      0.63      5000\n",
            "\n",
            "[[175   0   0   1   0   0   0   3   0   0   1   0   5   1   0   0   5   2\n",
            "    7   0   1   0   1   1   3   0]\n",
            " [  0 121   0   8   0   1   0   2  21   0   1   0   3   0   0   0   1  14\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0 126   0   5   0   9   0   0   0  17   0   4   0   3   0   3   1\n",
            "    1   1   1   0   0   0   0   0]\n",
            " [  0  18   0 149   0   0   0   1  12   7   2   0   2   0  12   1   0   6\n",
            "    5   0   0   0   0   1   0   0]\n",
            " [  0   2   2   2  74   0  29   0  12   0   7   0   0   0   0   0  14   1\n",
            "    7   2   0   0   0  33   0   6]\n",
            " [  0   8   0   5   0 142   5   0   1   0   0   0   1   3   0  11   2   3\n",
            "    2   4   0   0   3   1   3   0]\n",
            " [  2   5  36   3   0   2 112   0   3   0   4   0   2   0   4   0  15   5\n",
            "    5   0   0   0  10   0   0   0]\n",
            " [  1   6   0  15   0   5   2  53   1   0  12   0   6   2  30   0   2  14\n",
            "    0   0   4   0   3  19   3   0]\n",
            " [  0   5   0   9   4   6   0   0 153  13   0   1   0   0   0   2   2   0\n",
            "    8   1   0   0   0   0   0   1]\n",
            " [  0   5   0   8   0   3   0   0  10 137   0   0   0   0   1   2   1   2\n",
            "   12   0   0   0   0   2   0   0]\n",
            " [  0   7   1   6  17   0   6   1   1   0  79   0   3   1   0   0   1  25\n",
            "    0   2   4   0   0  22   1   0]\n",
            " [  0   4   0   0   1   0   6   0   0  12  11 155   0   0   0   0   9   2\n",
            "    2   0   0   0   0   3   0   0]\n",
            " [  3   3   0   0   0   0   0   2   0   0   4   0 171   0   0   0   0   1\n",
            "    0   0   0   0   3   0   0   0]\n",
            " [  2   2   0   6   0   0   0  22   1   0   3   0   6 119  10   1   0   7\n",
            "    0   0   2   8   9   0   0   0]\n",
            " [  3   2   1   6   0   0   8   2  10   0   3   0   7   1 123   1   4   7\n",
            "    0   0   0   0   3   0   0   0]\n",
            " [  0   3   0   9   0  18   5   1   0   0   0   0   0   2   1 150   1   0\n",
            "    1   0   0   1  11   0   4   0]\n",
            " [  6   2   0   3   0   0   3   0   5   0   1   2   3   0  46   0 116   6\n",
            "   20   0   0   0   2   1   1   0]\n",
            " [  0  21   0  16   0   0   0   6   4   7   6   0   7   1   4   0   3 133\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [ 12  30   1   3   5   4   3   1  15   1   2   1   0   0   0   0   7   2\n",
            "   54   6   1   1   0  26   1  22]\n",
            " [  0   0   0   1   1   8   6   1   0   0   8   0   1   0   0   0   0   2\n",
            "    3 133   0   4   0   5  10   1]\n",
            " [  0   0   4   2   0   0   2   7   0   0   9   1  18   4  11   0   3   0\n",
            "    0   0 151   0   2   1   0   0]\n",
            " [  0   6   0   0   0   2   1   1   0   0   0   0   3   1   0   3   0   0\n",
            "    1   0   0 130  18   0   2   0]\n",
            " [  0   4   0   0   0   0   0   2   0   0   0   0   9   2   4   1   0   0\n",
            "    0   0   0  14 131   0   0   0]\n",
            " [  0  12   0   5   2   0   0   0  13   1  10   1   0   0  20   1   0   0\n",
            "    6   6   4   0   0 100   1   4]\n",
            " [  0   0   0   3   0  13   0   0   0   0   0   0   3   1   1   2   7   0\n",
            "    8  24   3  49   5   0  64   0]\n",
            " [  3   0   0   2   2   3   0   0  22   2   3   3   0   0   0   0   1   4\n",
            "   25   5   0   0   0   5   0 114]]\n"
          ]
        }
      ]
    }
  ]
}